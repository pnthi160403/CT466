{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mask import (\n",
    "    create_decoder_atn_mask,\n",
    "    create_encoder_atn_mask,\n",
    ")\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "src_len = 4\n",
    "tgt_len = 5\n",
    "num_heads = 2\n",
    "\n",
    "min_val, max_val = 0, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 4]), torch.Size([2, 5]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = torch.randint(min_val, max_val, (batch_size, src_len))\n",
    "tgt = torch.randint(min_val, max_val, (batch_size, tgt_len))\n",
    "\n",
    "src.shape, tgt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_mask = create_encoder_atn_mask(src).type(torch.int64)\n",
    "tgt_mask = create_decoder_atn_mask(tgt).type(torch.int64)\n",
    "src_tgt_mask = create_encoder_atn_mask(src).type(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[8, 6, 4, 3]]],\n",
       "\n",
       "\n",
       "        [[[5, 0, 2, 9]]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1, 0, 0, 0, 0],\n",
       "          [1, 0, 0, 0, 0],\n",
       "          [1, 0, 0, 0, 0],\n",
       "          [1, 0, 0, 0, 0],\n",
       "          [1, 0, 0, 0, 0]]],\n",
       "\n",
       "\n",
       "        [[[1, 0, 0, 0, 0],\n",
       "          [1, 1, 0, 0, 0],\n",
       "          [1, 1, 0, 0, 0],\n",
       "          [1, 1, 0, 1, 0],\n",
       "          [1, 1, 0, 1, 0]]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_src_weight = torch.randint(min_val, max_val, (batch_size, num_heads, src_len, src_len)).type(torch.float32)\n",
    "attn_tgt_weight = torch.randint(min_val, max_val, (batch_size, num_heads, tgt_len, tgt_len)).type(torch.float32)\n",
    "attn_src_tgt_weight = torch.randint(min_val, max_val, (batch_size, num_heads, tgt_len, src_len)).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = attn_src_weight.masked_fill(\n",
    "    mask=src_mask == 0,\n",
    "    value=float(\"-inf\"),\n",
    ")\n",
    "w2 = attn_tgt_weight.masked_fill(\n",
    "    mask=tgt_mask == 0,\n",
    "    value=float(\"-inf\"),\n",
    ")\n",
    "w3 = attn_src_tgt_weight.masked_fill(\n",
    "    mask=src_tgt_mask == 0,\n",
    "    value=float(\"-inf\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 2, 4, 4]), torch.Size([2, 2, 5, 5]), torch.Size([2, 2, 5, 4]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_src_weight.shape, attn_tgt_weight.shape, attn_src_tgt_weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 1, 4]), torch.Size([2, 1, 5, 5]), torch.Size([2, 1, 1, 4]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_mask.shape, tgt_mask.shape, src_tgt_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 2, 4, 4]), torch.Size([2, 2, 5, 5]), torch.Size([2, 2, 5, 4]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.shape, w2.shape, w3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 4, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_mask_expand = src_mask.expand(-1, -1, attn_src_weight.size(2), -1).expand(-1, attn_src_weight.size(1), -1, -1)\n",
    "src_mask_expand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[8, 6, 4, 3],\n",
       "          [8, 6, 4, 3],\n",
       "          [8, 6, 4, 3],\n",
       "          [8, 6, 4, 3]],\n",
       "\n",
       "         [[8, 6, 4, 3],\n",
       "          [8, 6, 4, 3],\n",
       "          [8, 6, 4, 3],\n",
       "          [8, 6, 4, 3]]],\n",
       "\n",
       "\n",
       "        [[[5, 0, 2, 9],\n",
       "          [5, 0, 2, 9],\n",
       "          [5, 0, 2, 9],\n",
       "          [5, 0, 2, 9]],\n",
       "\n",
       "         [[5, 0, 2, 9],\n",
       "          [5, 0, 2, 9],\n",
       "          [5, 0, 2, 9],\n",
       "          [5, 0, 2, 9]]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_mask_expand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_expand = attn_src_weight.masked_fill(\n",
    "    mask=src_mask_expand == 0,\n",
    "    value=float(\"-inf\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 4, 4])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1_expand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]],\n",
       "\n",
       "         [[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]]],\n",
       "\n",
       "\n",
       "        [[[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]],\n",
       "\n",
       "         [[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1_expand == w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_mask_expand = tgt_mask.expand(-1, attn_tgt_weight.size(1), -1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2_expand = attn_tgt_weight.masked_fill(\n",
    "    mask=tgt_mask_expand == 0,\n",
    "    value=float(\"-inf\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[True, True, True, True, True],\n",
       "          [True, True, True, True, True],\n",
       "          [True, True, True, True, True],\n",
       "          [True, True, True, True, True],\n",
       "          [True, True, True, True, True]],\n",
       "\n",
       "         [[True, True, True, True, True],\n",
       "          [True, True, True, True, True],\n",
       "          [True, True, True, True, True],\n",
       "          [True, True, True, True, True],\n",
       "          [True, True, True, True, True]]],\n",
       "\n",
       "\n",
       "        [[[True, True, True, True, True],\n",
       "          [True, True, True, True, True],\n",
       "          [True, True, True, True, True],\n",
       "          [True, True, True, True, True],\n",
       "          [True, True, True, True, True]],\n",
       "\n",
       "         [[True, True, True, True, True],\n",
       "          [True, True, True, True, True],\n",
       "          [True, True, True, True, True],\n",
       "          [True, True, True, True, True],\n",
       "          [True, True, True, True, True]]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2_expand == w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length = 0\n",
      "Mask\n",
      "tensor([[[[49, 43, 86, 60, 65],\n",
      "          [84, 90,  1, 67, 19],\n",
      "          [74, 21, 57, 11, 38],\n",
      "          [31, 16, 19,  2, 41],\n",
      "          [40, 66, 78, 79, 84]]]])\n",
      "Mask slice\n",
      "tensor([[[[49, 43, 86]]]])\n",
      "\n",
      "Length = 1\n",
      "Mask\n",
      "tensor([[[[49, 43, 86, 60, 65],\n",
      "          [84, 90,  1, 67, 19],\n",
      "          [74, 21, 57, 11, 38],\n",
      "          [31, 16, 19,  2, 41],\n",
      "          [40, 66, 78, 79, 84]]]])\n",
      "Mask slice\n",
      "tensor([[[[84, 90,  1, 67]]]])\n",
      "\n",
      "Length = 2\n",
      "Mask\n",
      "tensor([[[[49, 43, 86, 60, 65],\n",
      "          [84, 90,  1, 67, 19],\n",
      "          [74, 21, 57, 11, 38],\n",
      "          [31, 16, 19,  2, 41],\n",
      "          [40, 66, 78, 79, 84]]]])\n",
      "Mask slice\n",
      "tensor([[[[74, 21, 57, 11, 38]]]])\n",
      "\n",
      "Length = 3\n",
      "Mask\n",
      "tensor([[[[49, 43, 86, 60, 65],\n",
      "          [84, 90,  1, 67, 19],\n",
      "          [74, 21, 57, 11, 38],\n",
      "          [31, 16, 19,  2, 41],\n",
      "          [40, 66, 78, 79, 84]]]])\n",
      "Mask slice\n",
      "tensor([[[[16, 19,  2, 41]]]])\n",
      "\n",
      "Length = 4\n",
      "Mask\n",
      "tensor([[[[49, 43, 86, 60, 65],\n",
      "          [84, 90,  1, 67, 19],\n",
      "          [74, 21, 57, 11, 38],\n",
      "          [31, 16, 19,  2, 41],\n",
      "          [40, 66, 78, 79, 84]]]])\n",
      "Mask slice\n",
      "tensor([[[[78, 79, 84]]]])\n",
      "\n",
      "tensor([[[0.0689],\n",
      "         [0.1116],\n",
      "         [0.1082],\n",
      "         [0.0783],\n",
      "         [0.2007]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiheadSlidingWindowSelfAttention(nn.Module):\n",
    "    def __init__(self, embed_size, num_heads, window_size):\n",
    "        super(MultiheadSlidingWindowSelfAttention, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.num_heads = num_heads\n",
    "        self.window_size = window_size\n",
    "        self.head_dim = embed_size // num_heads\n",
    "        \n",
    "        assert (\n",
    "            self.head_dim * num_heads == embed_size\n",
    "        ), \"Embedding size needs to be divisible by num_heads\"\n",
    "        \n",
    "        self.query = nn.Linear(embed_size, embed_size)\n",
    "        self.key = nn.Linear(embed_size, embed_size)\n",
    "        self.value = nn.Linear(embed_size, embed_size)\n",
    "        self.fc_out = nn.Linear(embed_size, embed_size)\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim]))\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        batch_size, seq_length, embed_size = x.shape\n",
    "\n",
    "        # Tính toán Q, K, V và reshape thành multi-head\n",
    "        Q = self.query(x).view(batch_size, seq_length, self.num_heads, self.head_dim)\n",
    "        K = self.key(x).view(batch_size, seq_length, self.num_heads, self.head_dim)\n",
    "        V = self.value(x).view(batch_size, seq_length, self.num_heads, self.head_dim)\n",
    "\n",
    "        Q = Q.permute(0, 2, 1, 3)\n",
    "        K = K.permute(0, 2, 1, 3)\n",
    "        V = V.permute(0, 2, 1, 3)\n",
    "\n",
    "        half_window = self.window_size // 2\n",
    "        attention = torch.zeros(batch_size, self.num_heads, seq_length, self.head_dim).to(x.device)\n",
    "        \n",
    "        for i in range(seq_length):\n",
    "            start = max(0, i - half_window)\n",
    "            end = min(seq_length, i + half_window + 1)\n",
    "            \n",
    "            Q_slice = Q[:, :, i, :].unsqueeze(2)\n",
    "            K_slice = K[:, :, start:end, :]  # (batch_size, num_heads, k_len, head_dim)\n",
    "            V_slice = V[:, :, start:end, :]  # (batch_size, num_heads, k_len, head_dim)\n",
    "            \n",
    "            # Tính attention scores\n",
    "            scores = torch.matmul(Q_slice, K_slice.transpose(-2, -1)) / self.scale\n",
    "            \n",
    "            print(f\"Length = {i}\")\n",
    "            # Áp dụng mask\n",
    "            print(\"Mask\")\n",
    "            print(mask)\n",
    "            if mask is not None:\n",
    "                mask_slice = mask[:, :, i, start:end].unsqueeze(2)\n",
    "                print(\"Mask slice\")\n",
    "                print(mask_slice)\n",
    "                print()\n",
    "                scores = scores.masked_fill(mask_slice == 0, float('-inf'))\n",
    "            \n",
    "            attention_weights = F.softmax(scores, dim=-1)\n",
    "            \n",
    "            # Tính giá trị attention\n",
    "            attention[:, :, i, :] = torch.matmul(attention_weights, V_slice).squeeze(2)\n",
    "\n",
    "        # Kết hợp các đầu attention và áp dụng phép chiếu tuyến tính\n",
    "        attention = attention.permute(0, 2, 1, 3).contiguous()\n",
    "        attention = attention.view(batch_size, seq_length, embed_size)\n",
    "        out = self.fc_out(attention)\n",
    "\n",
    "        return out\n",
    "\n",
    "# Ví dụ sử dụng\n",
    "embed_size = 1\n",
    "num_heads = 1\n",
    "window_size = 5\n",
    "seq_length = 5\n",
    "batch_size = 1\n",
    "\n",
    "model = MultiheadSlidingWindowSelfAttention(embed_size, num_heads, window_size)\n",
    "x = torch.randn(batch_size, seq_length, embed_size)\n",
    "\n",
    "# Tạo mask (ví dụ: mask có kích thước batch_size * seq_length * seq_length)\n",
    "mask = torch.randint(0, 100, (batch_size, num_heads, seq_length, seq_length))\n",
    "# Ví dụ: không cho attention tới các vị trí thứ 3 và thứ 7 trong mỗi chuỗi của mỗi batch\n",
    "# mask[:, :, 2] = 0\n",
    "# mask[:, :, 6] = 0\n",
    "\n",
    "output = model(x, mask)\n",
    "print(output)  # Should output (batch_size, seq_length, embed_size)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
